# üçì FreshNET: Lightweight CNN for Fruit/Vegetable Freshness Classification

## üß† Overview

**FreshNET** is a custom convolutional neural network inspired by the architectural principles of MobileNet, as introduced in the paper _‚ÄúMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications‚Äù_ by Howard et al. It uses **Depthwise Separable Convolutions** and **skip connections** to achieve a lightweight yet expressive architecture, tailored for fine-grained classification of fresh vs. rotten fruits and vegetables.

The model was trained on a custom dataset of ~40,000 high-resolution images and is designed to be deployable on **edge devices**. 

I am currently quantizing the model with QAT. One of the DepthwiseSeparableConvolution layers appears to be receiving a float32 input when it expects a quint8. I‚Äôm working to resolve this type mismatch, after which I will run the test loop and report the final accuracy of the quantized model.

Download the **unquantized model weights** from here: https://huggingface.co/vjhawar12/FreshNET/resolve/main/FreshNET.pth

---

## üéØ Motivation

After completing my project **D.E.L.P.H.I** (see companion repo), an assistive device that employs computer vision (CV) for object detection, I was curious to see how deep learning models could be optimized for deployment on edge devices. I read the pytorch docs on Quantization and wanted to explore the topic further, so I deceided to work on a classifier that balanced **accuracy** with **model size**. 

After exploring standard CNNs, I studied MobileNet and adapted its concepts into **FreshNET**, modifying the architecture to better suit the task of **freshness detection** in fruits and vegetables.

---

### üìä FreshNET Model Comparison (Original vs Quantized)

| Metric                  | Original Model (FP32) | Quantized Model (INT8, QAT) |
|-------------------------|------------------------|------------------------------|
| Accuracy (Test)         | 97.8%                  | TBD                          |
| Model Size              | 11.11 MB               | **0.24 MB**                  |
| Size Reduction          | ‚Äî                      | ~46√ó smaller                 |
| Quantization Type       | ‚Äî                      | QAT (Quantization-Aware Training) |
| Target Architecture     | x86_64                 | ARM                          |

---

## üß™ Tech Stack

- PyTorch
- Custom MobileNet-style architecture
- Mixed Precision Training (AMP)
- Cosine Annealing LR Scheduler with Linear Warmup
- Torchvision image transforms & dataloaders
- Depthwise Separable Convolutions from scratch

---

## üß© Next Experiments

- Try pretrained MobileNetV2 as a benchmark
- Compare training time and accuracy
- Evaluate inference latency on Raspberry Pi / Jetson Nano

---
