{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vjhawar12/FreshNET/blob/main/FreshNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dEyze5_tgqY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBAPWxBiWgPH",
        "outputId": "d7d95ef1-0a67-470d-a997-cea8a4bf0a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=2hDyy1VYRxMwp31IG3oT9g4QqA3lzh&prompt=consent&token_usage=remote&access_type=offline&code_challenge=9qVHTsGss38khnJHTxlMRpz1Fa5dPabujUwwlp7ZfqE&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: "
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I26bJ0bd0ck"
      },
      "outputs": [],
      "source": [
        "!gcloud config set project freshnet-466505"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDtB44SnpQ8M"
      },
      "outputs": [],
      "source": [
        "!cd /content/dataset && gcloud storage cp --recursive gs://fruit-images-freshnet ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWsxLrTEvlqB",
        "outputId": "846769aa-c23b-42fa-8632-901fb695757d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/dataset && ls'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!cd /content/dataset && ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9Lp9Z9wJEd"
      },
      "outputs": [],
      "source": [
        "path_to_train_imgs = \"\"\n",
        "path_to_test_imgs = \"\"\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "RANDOM_SEED = 42\n",
        "TRAIN_SIZE, VAL_SIZE = 0.8, 0.2\n",
        "IMG_SIZE = 320 # Original images are ~400*400 px so resizing them to 320 retains detail while reducing computational cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXmvl6h6stv_"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    # additional preprocessing\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ_x5765vvpn"
      },
      "outputs": [],
      "source": [
        "full_train_data = ImageFolder(path_to_train_imgs, transform=train_transform)\n",
        "test_data = ImageFolder(path_to_test_imgs, transform=test_transform)\n",
        "train_data, val_data = random_split(full_train_data, [TRAIN_SIZE, VAL_SIZE], generator=RANDOM_SEED)\n",
        "\n",
        "print(f\"{full_train_data.class_to_idx} \\n {train_data.class_to_idx} \\n {test_data.class_to_idx}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_a2E-zQxN6i"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=10)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedResidual(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, exp_factor, downsample_factor, kernel_size=3):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.exp_factor = exp_factor\n",
        "    self.downsample_factor = downsample_factor\n",
        "    self.kernel_size = kernel_size\n",
        "\n",
        "    out = self.in_channels * self.exp_factor\n",
        "\n",
        "    self.block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=self.in_channels, out_channels=out, kernel_size=1, stride=1, groups=1), # expansion\n",
        "        nn.Conv2d(in_channels=out, out_channels=out, kernel_size=self.kernel_size, stride=self.downsample_factor, groups=out), # depthwise\n",
        "        nn.Conv2d(in_channels=out, out_channels=self.out_channels, kernel_size=1, stride=1, groups=1), # pointwise\n",
        "        nn.ReLU6(), # output âˆˆ [0, 6] ==> more efficient than regular ReLU\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "VbsxVpDvSGbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDb7UN4x0Z0z"
      },
      "outputs": [],
      "source": [
        "class FreshNET_CNN(nn.Module):\n",
        "\n",
        "  \"\"\"\n",
        "  FreshNET applies the concept of depthwise and pointwise convolutions as introduced in the MobileNet paper. The key idea is to decouple spatial filtering and channel mixing,\n",
        "  which are both handled together in a standard convolution (like a 3*3*3 kernel) into two more efficient operations.\n",
        "\n",
        "  This separation is implemented in InvertedResidual class. Each instance consists of:\n",
        "  - A pointwise 1*1 convolution for channel expansion, increasing feature dimensionality.\n",
        "  - A depthwise 3*3 convolution applied independently per channel for spatial filtering.\n",
        "  - Another pointwise convolution to project back to a lower-dimensional space.\n",
        "\n",
        "  This design significantly reduces computational cost while maintaining high representational power. There are 10 layers, of which 7 are InvertedResidual layers.\n",
        "  Each InvertedResidual layer consists of 1-4 InvertedResidual instances. Within the InvertedResidual layer, there are non-linear activation functions.\n",
        "\n",
        "  To mitigate potential accuracy trade-offs, techniques such as skip connections and strong data augmentation are applied to help improve generalization and performance\n",
        "  on validation data.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # silu is good for vanishing gradients and can be applied in the later layers where ReLU might not be as effective (dead neurons)\n",
        "    silu = nn.SiLU()\n",
        "\n",
        "    # dropout regularization\n",
        "    dropout_aggressive = nn.Dropout(0.3)\n",
        "    dropout_mild = nn.Dropout(0.1)\n",
        "\n",
        "    # initial regular convolution\n",
        "    initial_conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2) # 320*320*3 --> 160*160*32\n",
        "\n",
        "    # inverted residual block 1: 160*160*32 --> 160*160*16, channel expansion = 1\n",
        "    block_1 = nn.Sequential(\n",
        "        InvertedResidual(32, 16, 1, 1)\n",
        "    )\n",
        "\n",
        "    # inverted residual block 2: 160*160*16 --> 80*80*24, channel expansion = 6\n",
        "    block_2 = nn.Sequential(\n",
        "        InvertedResidual(16, 24, 6, 2),\n",
        "        InvertedResidual(24, 24, 6, 1)\n",
        "    )\n",
        "\n",
        "    # inverted residual block 3: 80*80*24 --> 40*40*32, channel expansion = 6\n",
        "    block_3 = nn.Sequential(\n",
        "        InvertedResidual(24, 32, 6, 2),\n",
        "        InvertedResidual(32, 32, 6, 1),\n",
        "        InvertedResidual(32, 32, 6, 1),\n",
        "    )\n",
        "\n",
        "    # inverted residual block 4: 40*40*32 --> 20*20*64, channel expansion = 6\n",
        "    block_4 = nn.Sequential(\n",
        "        InvertedResidual(32, 64, 6, 2),\n",
        "        InvertedResidual(64, 64, 6, 1),\n",
        "        InvertedResidual(64, 64, 6, 1),\n",
        "        InvertedResidual(64, 64, 6, 1),\n",
        "    )\n",
        "\n",
        "    # inverted residual block 5: 20*20*64 --> 20*20*96, channel expansion = 6\n",
        "    block_5 = nn.Sequential(\n",
        "        InvertedResidual(64, 96, 6, 1),\n",
        "        InvertedResidual(96, 96, 6, 1),\n",
        "        InvertedResidual(96, 96, 6, 1),\n",
        "    )\n",
        "\n",
        "    # inverted residual block 6: 20*20*96 --> 10*10*160, channel expansion = 6\n",
        "    block_6 = nn.Sequential(\n",
        "        InvertedResidual(96, 160, 6, 2),\n",
        "        InvertedResidual(160, 160, 6, 1),\n",
        "        InvertedResidual(160, 160, 6, 1),\n",
        "    )\n",
        "\n",
        "    # inverted residual block 7: 10*10*160 --> 10*10*320, channel expansion = 6\n",
        "    block_7 = nn.Sequential(\n",
        "        InvertedResidual(160, 320, 6, 1)\n",
        "    )\n",
        "\n",
        "    # final regular convolution\n",
        "    final_conv = nn.Conv2d(in_channels=320, out_channels=1280, kernel_size=1, stride=1) # 10*10*320 --> 10*10*1280\n",
        "\n",
        "    \"\"\"\n",
        "      MaxPooling is often preferred for highlighting dominant features, but it can be too aggressive in lightweight models\n",
        "      like MobileNet or EfficientNet, which already have low spatial resolution. It can discard valuable spatial\n",
        "      information. Average Pooling computes the average of nearby pixels, preserving more context. This makes it more\n",
        "      suitable for compact architectures like this one.\n",
        "    \"\"\"\n",
        "\n",
        "    avg_pool = nn.AvgPool2d(10) # 10*10*1280 --> 1*1*1280\n",
        "\n",
        "    # fully connected layers\n",
        "    fc_1 = nn.Linear(in_features=1280, out_features=500)\n",
        "    fc_2 = nn.Linear(in_features=500, out_features=2)\n",
        "\n",
        "    # layer order\n",
        "    self.layers = nn.ModuleList(\n",
        "        [\n",
        "            initial_conv,\n",
        "\n",
        "            block_1\n",
        "            block_2,\n",
        "            block_3,\n",
        "            block_4,\n",
        "\n",
        "            dropout_mild,\n",
        "\n",
        "            block_5,\n",
        "            block_6,\n",
        "            block_7,\n",
        "\n",
        "            final_conv,\n",
        "\n",
        "            avg_pool, silu, # ReLU in later layers can lead to problems, so I used a different activation function here\n",
        "\n",
        "            fc_1, silu,\n",
        "\n",
        "            dropout_aggressive,\n",
        "\n",
        "            fc_2\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCIQf4NUxhgv"
      },
      "outputs": [],
      "source": [
        "cnn = FreshNET_CNN()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  pass"
      ],
      "metadata": {
        "id": "VIoxmncQ4MDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate():\n",
        "  pass"
      ],
      "metadata": {
        "id": "561tlOBf4GOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  pass"
      ],
      "metadata": {
        "id": "Tk4rp3ox4I7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVlrADe0p+v6+GM9LISY/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}